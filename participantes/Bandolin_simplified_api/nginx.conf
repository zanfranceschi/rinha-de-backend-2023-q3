worker_processes auto;

events {
    worker_connections 10000;
     use epoll;                 # Use efficient event model (specific to Linux).
     multi_accept on;          # Enable accepting multiple connections at a time.
}

http {
  upstream backend {
    server api1:9000;
    server api2:9000;
    keepalive 1000;
  }

  server {
      listen 0.0.0.0:9999;
      server_name localhost;

      open_file_cache max=200000 inactive=20s;
      open_file_cache_valid 30s;
      open_file_cache_min_uses 2;
      open_file_cache_errors on;

      access_log off;

      sendfile on;

      tcp_nopush on;

      tcp_nodelay on;
      server_tokens off;

      gzip on;
      gzip_comp_level 2;
      gzip_proxied any;
      gzip_vary on;
      gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

      reset_timedout_connection on;
      client_body_timeout 10;
      send_timeout 6;
      keepalive_timeout 30;
      keepalive_requests 100000;

      root /api/api;

       location / {
          try_files $uri /index.php$is_args$args;
      }

      location ~ ^/(status|ping)$ {
        fastcgi_pass backend;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        fastcgi_param SCRIPT_NAME $fastcgi_script_name;
        include fastcgi_params;
     }

     location /nginx_status {
         stub_status;
     }

     location ~ \.php {
        try_files $uri =404;
        fastcgi_split_path_info ^(.+\.php)(/.+)$;
        include fastcgi_params;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        fastcgi_param SCRIPT_NAME $fastcgi_script_name;
        fastcgi_index index.php;
        fastcgi_pass backend;
        fastcgi_keep_conn on;
        fastcgi_read_timeout 40s;
        proxy_read_timeout 40s;
    }
  }
}
